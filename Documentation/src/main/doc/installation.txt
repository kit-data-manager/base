[[ChapterInstallation]]
Installing KIT Data Manager
---------------------------

The following sections describe the basic installation steps of KIT Data Manager. After following the installation instructions you'll have all available KIT Data Manager 
services deployed in a Tomcat environment accessible via REST interfaces. Everything beyond, e.g. graphical user interfaces or advanced deployment scenarios, are not 
part of this documentation.

Prerequisites
~~~~~~~~~~~~~
In order to be able to provide KIT Data Manager services you'll need at least the following software components installed: 

* Java SE Development Kit 8
* Apache Tomcat 7 (Tomcat 8 is currently not supported)
* PostgreSQL 9.1+
* RabbitMQ 3.6.5+
* Elasticsearch 5.1+ 

In principal it is possible to install KIT Data Manager on every operating system. For simplicity, this documentation only covers the installation on a Unix-based system 
(namely Ubuntu 16.04 LTS) in detail.

Software Installation
~~~~~~~~~~~~~~~~~~~~~
At first, please install the required software packages. Therefor, you can use either the package manager of your system or you can download the packages manually. 
The following steps are based on an installation using Apt:

[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo apt-get install postgresql
Reading package lists... Done
Building dependency tree       
Reading state information... Done
postgresql is already the newest version.
user@localhost:/home/user$ sudo apt-get install openjdk-8-jdk
Reading package lists... Done
Building dependency tree       
Reading state information... Done
openjdk-8-jdk is already the newest version.
user@localhost:/home/user$ sudo apt-get install tomcat7
Reading package lists... Done
Building dependency tree       
Reading state information... Done
tomcat7 is already the newest version.
user@localhost:/home/user$ sudo apt-get install havegd
Reading package lists... Done
Building dependency tree       
Reading state information... Done
havegd is already the newest version.
user@localhost:/home/user$ sudo apt-get install rabbitmq-server
Reading package lists...
Building dependency tree...
Reading state information...
rabbitmq-server is already the newest version.
user@localhost:/home/user$
--------------------------------------
As elasticsearch is not available via a software repository it has to be downloaded
and configured first.

Elasticsearch
^^^^^^^^^^^^^
If an older version of Elasticsearch is already installed an upgrade should be made to 
preserve existing indices. (See links below)

[NOTE]
*_Cluster name_* and *_hostname_* needed to be known during further installation steps.


*Step1:* Download newest Version (5.X) of Elasticsearch (Tested with version 5.1.1).
[source,sh]
--------------------------------------
user@localhost:/home/user$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.1.1.deb
--------------------------------------

*Step 2:* Install Elasticsearch
[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo dpkg -i elasticsearch-5.1.1.deb
--------------------------------------

*Step 3:* Configuring Elasticsearch
The Elasticsearch configuration file (elasticsearch.yml) in the _/etc/elasticsearch_ directory
has to be modified:
To avoid conflicts with other installations a unique clustername has to be chosen.
Look for the corresponding line remove the leading # and change the value:

cluster.name: KITDataManager@`hostname`


Set `hostname` to the hostname of the host running elasticsearch or to another, unique value and keep the value of 'cluster.name' for later use.

[IMPORTANT]
Please check also the https://www.elastic.co/guide/en/elasticsearch/reference/current/system-config.html[System Configuration] section of elasticsearch, 
especially for increasing the number of open file descriptors.

*Step 4:* Configure Elasticsearch as daemon and start service
[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo /bin/systemctl daemon-reload
user@localhost:/home/user$ sudo /bin/systemctl enable elasticsearch.service
user@localhost:/home/user$ sudo /bin/systemctl start elasticsearch.service
--------------------------------------
That's it. Now continue setting up KIT Data Manager to index metadata to Elasticsearch. 

[IMPORTANT]
Since elastic version 5.0.0 the ports (9200 and 9300) for accessing Elasticsearch 
are only accessible from localhost. Dowever, everyone who is able to access Elasticsearch 
has all privileges, e.g. also deleting the index. For production environments further security measures are recommended.

External Links
++++++++++++++
For more detailed information on how to setup Elasticsearch on Ubuntu please refer to the following
links.

https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-ubuntu-14-04[Installation and configuration of Elasticsearch]

https://www.elastic.co/guide/en/elasticsearch/reference/current/system-config.html[Elasticsearch System Configuration]

https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-service.html[Run Elasticsearch as service]

https://www.elastic.co/guide/en/elasticsearch/reference/current/setup-upgrade.html[Upgrade from old version]

Setup KIT Data Manager
^^^^^^^^^^^^^^^^^^^^^^
Now you have installed and configured all software packages you need to run KIT Data Manager. Not later than now you should extract your KIT Data Manager binary distribution archive 
to a preferred location which will be referred below as `$KITDM_LOCATION`. Afterwards change the ownership to tomcat7:tomcat7. 

[source,sh]
--------------------------------------
user@localhost:/home/user$ cd $KITDM_LOCATION
user@localhost:/home/user$ unzip KITDM-<Version>.zip
user@localhost:/home/user$ sudo chown -R tomcat7:tomcat7 KITDM
user@localhost:/home/user$
--------------------------------------

There should now be the application itself and a number of configuration files and scripts, which are covered later, available at $KITDM_LOCATION. 
In the following steps the relational database used by KIT Data Manager is prepared. The first step is setting a password for the database user that was created 
during installation.

[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo -u postgres psql postgres
psql (9.1.13)
Type "help" for help.

postgres=#\password postgres
--------------------------------------

Now set a password for the database user `postgres` and keep it in mind for later configuration steps. Now the KIT Data Manager database can be created. 

[source,sh]
--------------------------------------
postgres=#create database datamanager;
CREATE DATABASE
postgres=#\q
--------------------------------------
Alternatively this can also be done from commandline.
[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo -u postgres createdb datamanager
user@localhost:/home/user$ 
--------------------------------------

A database named `datamanager` has been created and can be set up. For this purpose, a file named `$KITDM_LOCATION/sql/schema.sql` is provided as part of your KIT Data 
Manager distribution. Apply the SQL statements in this file to the database by the following command:

[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo -u postgres psql -U postgres -d datamanager -f $KITDM_LOCATION/sql/schema.sql
CREATE TABLE
CREATE SEQUENCE
ALTER SEQUENCE
[...]
CREATE INDEX
user@localhost:/home/user$ 
--------------------------------------

[NOTE]
Adding sample data is not longer necessary since KIT DM version 1.5. For security reasons, a first start wizard has been implemented for creating the administrator user and perform basic configuration.

In the next step you have to deploy the KIT Data Manager and WebDav Web applications on the local Tomcat server. Therefor, copy the files `$KITDM_LOCATION/webapp/KITDM.xml` and `$KITDM_LOCATION/webapp/webdav.xml` to 
`$CATALINA_HOME/conf/Catalina/localhost/`. In our case this would be `/var/lib/tomcat7/conf/Catalina/localhost/`. 

[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo cp $KITDM_LOCATION/webapp/*.xml /var/lib/tomcat7/conf/Catalina/localhost/
user@localhost:/home/user$ 
--------------------------------------

[[WebDavLibraries]]
Now, the custom WebDav implementation must be 'deployed' to Tomcat. Therefor, execute the following commands:
 
[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo cp $KITDM_LOCATION/tomcat-ext/*.jar /usr/share/tomcat7/lib/
user@localhost:/home/user$ sudo chown tomcat7:tomcat7 /usr/share/tomcat7/lib/*.jar
user@localhost:/home/user$ 
--------------------------------------

This will copy a couple of libraries to your Tomcat installation, which should be: 

* commons-codec-1.7.jar
* logback-classic-1.0.11.jar
* logback-core-1.0.11.jar
* postgresql-9.1-901.jdbc4.jar
* slf4j-api-1.7.5.jar
* tomcat-ext-1.1.1.jar

[NOTE]
The library versions as well as the JDBC driver (postgresql-9.1-901.jdbc4.jar) may differ, depending on the KIT DM version and your local installation. 

Finally, you have to modify `/var/lib/tomcat7/conf/Catalina/localhost/KITDM.xml` and `/var/lib/tomcat7/conf/Catalina/localhost/webdav.xml` in order to make `KITDM_LOCATION` point to the absolute value of `$KITDM_LOCATION`. 
Inside `/var/lib/tomcat7/conf/Catalina/localhost/webdav.xml` also set the correct values for `DB_HOST`, `DB_PORT`, `DB_NAME`, `DB_USER`, `DB_PASSWORD` to be able to access the user database. 
The default values according to the above configuration options are DB_HOST=localhost and DB_NAME=datamanager.Typically, DB_PORT should be 5432 for PostgreSQL, but might be different if this port was already in 
use during installation. DB_USER and DB_PASSWORD must be set to the previously created/chosen values.
 
Now, your KIT Data Manager services are ready for further configuration.

Basic Configuration
~~~~~~~~~~~~~~~~~~~

All configuration files of KIT Data Manager itself are located inside the web application folder, by default at `$KITDM_LOCATION/KITDM/WEB-INF/classes/`. Relevant configuration files are: 

META-INF/persistence.xml::
   Contains all JPA persistence units for database access. Values that must be changed are `DB_HOST`, `DB_PORT`, `DB_NAME`, `DB_USER`, `DB_PASSWORD`. The default values according to the above configuration options are
   DB_HOST=localhost and DB_NAME=datamanager. Typically, DB_PORT should be 5432 for PostgreSQL, but might be different if this port was already in use during installation. DB_USER and DB_PASSWORD must be set to the 
   previously created/chosen values.
datamanager.xml::
   Contains all KIT Data Manager settings. Typically, most of them can remain unchanged, except settings containing placeholder variables (e.g. `KITDM_LOCATION`, `HOSTNAME`,  and `ARCHIVE_STORAGE`). Database settings,
   e.g. for setting up the scheduler persistence backend, are typically the same as in the previous configuration file. Elasticsearch settings also has to be adapted. For more information, please refer to the comments inside datamanager.xml for more information.
logback.xml::
   The configuration of the logging framework. By default, all warnings and error messages are logged into the Tomcat temp folder located e.g. at `/tmp/tomcat7-tomcat7-tmp/` or `$CATALINA_HOME/temp/`, 
   but you can also set another value instead of `${java.io.tmpdir}/datamanager.log` as log file location at any time.

[NOTE]
Please go through all files at least during your first installation to check which settings are in there and which you have to change in order to get your KIT Data Manager instance running.

In order to be able to use KIT Data Manager as a repository system, at least one access point must be configured to allow data ingest and download. Since version 1.4 the default (and recommended) way to transfer data to and from 
KIT Data Manager is via the provided WebDav servlet as it offers several advantages:

1. The configuration effort, e.g. installing additional software packages, open ports and permission management, is reduced to a minimum.
2. The KIT Data Manager user management is seamlessly integrated with the WebDav servlet.
3. The WebDav servlet offers built-in authorization of resource access for KIT Data Manager users and groups.

The first step in order to enable WebDav access was already done in the last section by copying and modifying the file `$KITDM_LOCATION/webapp/webdav.xml` and the libraries located in 'tomcat-ext'. 
In the next step please check `$KITDM_LOCATION/webdav/WEB-INF/web.xml`. Typically, no changes are necessary here but the inline comments may help to understand which configuration options there are if 
customization gets necessary. The most relevant settings are in the section `<login-config>`. In this section the realm-name, which is set to `kitdm`, and the auth-method, which is set to DIGEST, are defined. 
Both values should remain unchanged if there is no necessity to change it. The reason therefor is, that if they change they must also be changed in the according section of `datamanager.xml`. 
[[WebDavConfig]]
There you'll find the configuration section:

[source, xml]
--------------------------------------
<authenticator class="edu.kit.dama.rest.util.auth.impl.HTTPAuthenticator">
     <authenticatorId>webdav</authenticatorId>
     <!--The HTTP realm needed if type is 'DIGEST'.-->
     <realm>kitdm</realm>
     <!--The type that must be either BASIC or DIGEST.-->
     <type>DIGEST</type>
 </authenticator>
--------------------------------------

The values of 'realm' and 'type' must match the configuration in the `web.xml` as the HTTPAuthenticator is used to generate the WebDav credentials for the KIT Data Manager users that are later used to authenticate. If there is a 
configuration mismatch, authentication will fail.

[NOTE]
NOW start/restart your Tomcat container in order to apply the configuration changes. 

The final step is now to register a new staging access point using WebDav access using the administration backend of KIT Data Manager. For this purpose please browse to
`http://localhost:8080/KITDM` at your KIT Data Manager machine. As this should be the first time accessing the installation, a wizard will appear guiding you through the initial setup. 

Please follow the wizard until you reach the third step. At this point you have to input `Base Url` and `Base Path`. The base Url look like http://myhost:8080/webdav depending on your local hostname, the Base Path should be 
the absolute path to `$KITDM_LOCATION/webdav`. At the end of the wizard the access point is committed to the database together with all other settings.

Enhanced Configuration
~~~~~~~~~~~~~~~~~~~~~~

[[ChapterORCIDLogin]]
ORCiD Login and Registration
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Since KIT Data Manager 1.4 user registration and login via ORCiD is supported. In order to enable ORCiD service access a couple of working steps are required. First, please go to  
link:https://orcid.org[ORCiD.org] and enable public API access for your account. You should be able to find it unter 'For Researchers" -> 'Developer Tools'. Provide application name, e.g. MyRepository, your website URL, 
e.g. http://myinstitution.org, a short description of your application and at least one redirect URI, which is the base URL of your KIT Data Manager instance, e.g. https://myhost:8080/KITDM You may also provide multiple redirect
URIs later in order to support other applications, too. 

After providing all information, you'll find Client ID and Client secret on the ORCiD page. Now, add these two tokens to 'datamanager.xml' into the according fields ('login.orcid.clientid' and 'login.orcid.clientsecret')
of the 'authorization' section. After (re-)starting your Tomcat instance you should see the optional ORCiD login when entering 'https://myhost:8080/KITDM'.

[NOTE]
From the configuration and implementation perspective, also B2ACCESS login is possible in the current version. However, as B2ACCESS is by default configured not to send any information helping to identify the user this 
feature has been disabled for the time being.

[[ChapterAuthorizationLessAccess]]
Authorization-less Access to Data Organization
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Section <<SectionRESTBasedDownload,REST-based Data Download>> describes a feature allowing to download data directly via the Data Organization REST endpoint. By default, this feature is disabled in order to avoid 
open access to repository content by accident. In order to enable the authorization-less access to defined nodes via the Data Organization REST endpoint you have to modify `$KITDM_LOCATION/KITDM/WEB-INF/web.xml`
and uncomment/change one or more of the following `init-param` nodes. 

There are four different parameter blocks, each for one `authorization-less access` type. You should decide which of them you really need as they require to organize you Digital Objects accordingly. The following table shows
all options, sample values and a short description.

[cols="m,n,o", options="header"]
|============================================================================================================================
|Parameter Name|Example Value|Description
|public.view.names|public;public2|List of Data Organization views that are publicly accessible. In the example, all elements stored in views named `public` and `public2` of all Digital Objects in the repository system are publicly accessible. Attention: You should never provide the `default` view here as this would open the entire data of a Digital Object.
|public.attribute.key|isOpen|A single attribute, which sets a node (either collection or file node) to be publicly accessible if an attribute with the provided name has been assigned to the node. In the example, all Data Organization nodes having the attribute `isOpen` assigned are publicly accessible. The attribute value is currently not evaluated.
|public.collection.node.access.allowed|false|Either `true` or `false`. Mainly for testing purposes to allow authorization-less access to entire collection nodes in all Digital Objects and all Data Organization views. It is recommended NOT to enable this option. 
|public.file.node.filter|(.*)\.jpg$|Regular expression granting public access to all file nodes in all Digital Objects and all Data Organization views for which the node name fulfills the regular expression. In the example, all nodes with the extension `jpg` are publicly available.
|============================================================================================================================

[NOTE]
Please refer to the inline documentation or the <<SectionRESTBasedDownload,according section>> in the architecture decription for details.

The following snippet shows the according configuration section in the KIT Data Manager's web.xml. 

[source, xml]
--------------------------------------
<!--[...]-->
<!--DataOrganization REST interface-->
    <servlet>
        <servlet-name>DataOrganizationServiceAdapter</servlet-name>
        <servlet-class>com.sun.jersey.spi.container.servlet.ServletContainer</servlet-class>
        <init-param>
            <param-name>com.sun.jersey.config.property.packages</param-name>
            <param-value>edu.kit.dama.rest.dataorganization.services.impl</param-value>
        </init-param>
        <init-param>
            <param-name>com.sun.jersey.api.json.POJOMappingFeature</param-name>
            <param-value>true</param-value>
        </init-param>
        <!--Access to all nodes in the listed view(s), multiple views are separated by ';', is allowed without any authorization. (Only recommended for special views) -->
        <!--init-param>
            <param-name>public.view.names</param-name>
            <param-value>public</param-value>
        </init-param-->
        <!--Access to all nodes having an attribute with the mentioned key assigned is allowed without any authorization. (Can be used for fine-grained selection) -->
        <!--init-param>
            <param-name>public.attribute.key</param-name>
            <param-value>public</param-value>
        </init-param-->
        <!--Access collection nodes (download zipped version of all children) is allowed (Typically not recommended) -->
        <!--init-param>
            <param-name>public.collection.node.access.allowed</param-name>
            <param-value>false</param-value>
        </init-param-->
        <!--Access file nodes is allowed if node name matches the provided pattern, e.g. (.*)\.jpg$ for all nodes ending with .jpg
        Note that special characters are only escaped with one slash, not with two as if the pattern is provided as string!-->
        <!--init-param>
            <param-name>public.file.node.filter</param-name>
            <param-value>(.*)\.jpg$</param-value>
        </init-param-->
        <load-on-startup>1</load-on-startup>
    </servlet>
    <servlet-mapping>
        <servlet-name>DataOrganizationServiceAdapter</servlet-name>
        <url-pattern>/rest/dataorganization/*</url-pattern>
    </servlet-mapping> 
<!--[...]-->
--------------------------------------

[WARNING]
Keep in mind that enabling authorization-less access affects `ALL` Digital Objects stored in the repository. Therefore, you should consider to configure this feature in a way, that the risk of opening data by accident is minimized, 
e.g. by using randomly generated view/attribute names or by using very specific name filter for accessing file nodes, e.g. the exact name instead of a too broad filter pattern.

[[ChapterCustomDataOrganization]]
Support for Ingest of Custom Data Organization Trees
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Basically, the ingest of custom Data Organization trees makes use of the default workflows already available with a basic KIT Data Manager installation. However, enabling this feature requires two configuration steps:

Add a StagingProcessor::
   Therefor, you can use the AdminUI as described in <<ChapterStagingProcessorConfiguration,this section>>. Add a new StagingProcessor using the implementation class 
   `edu.kit.dama.staging.processor.impl.ReferenceTreeIngestProcessor`. After adding a new processor select the CheckBoxes `Default` and `INGEST SUPPORTED`.
   Finish the configuration by clicking `Commit`. Now, this processor will check for each ingest if there is a custom Data Organization description provided.

Add a custom AdalapiProtocolConfiguration::
   This step is necessary if you plan to use the Staging Service to access remotely (via HTTP) accessible data provided as part of a custom Data Organization tree. By default, KIT Data Manager assumes that all HTTP URLs are accessible via the 
   WebDav protocol in with an interactive authentication performed by the user. For automated staging operations this is not useful. Therefore, in order to provide basic read access to HTTP URLs by the staging service, the access protocol as 
   well as the authentication has to be selected based on the accessed URL. Therefor, the protocol, hostname and port (if available) are used to create the unique identifier of a so called `AdalapiProtocolConfiguration`, which is stored in a 
   table with the same name and with the following columns: 

[cols="m,n,o,p,q", options="header"]
|============================================================================================================================
|id|authenticatorclass|customproperties|identifier|protocolclass
|1|edu.kit. dama.staging. adalapi.authenticator. KITDMAuthenticator|{"repository.context":"empty"}|http@remotehost|edu.kit. dama.staging. adalapi.protocol. SimpleHttp
|============================================================================================================================

[NOTE]
Please note that authenticatorclass and protocol class contain spaces in order to improve the readability of both values. Please remove the spaces when adding the values to the database.

For the time being the only two ways to add a new `AdalapiProtocolConfiguration` is manually adding a table row via SQL statement or programatically adding an entry via Java APIs. 
Furthermore, the exact values as shown above must be used. The only fields that change are the `id`, which has to be unique, and the `identifier` which also has to be unique and must be generated based on the URL that should be accessed. 
For manually adding a configuration via SQL statement, the following table shows some examples of identifiers for specific URLs: 

[cols="m,n", options="header"]
|============================================================================================================================
|Remote URL|Identifier
|`http://www.google.com/[...]`|`http@www.google.com`
|`https://myDomain:8443/[...]`|`https@myDomain:8443`
|`http://localhost:8080/webdav/[...]`|`http@localhost:8080`
|============================================================================================================================

Adding a configuration via Java APIs can be achieved as follows: 

[source,java]
--------------------------------------
//Create properties map containing properties that might be needed by the protocol and the authenticator implementation
Map<String, Object> properties = new HashMap<>();
properties.put("repository.context", "empty");
//Instantiate a new AdalapiProtocolConfiguration. The configuration identifier is obtained using the provided sample URL.
AdalapiProtocolConfiguration config = AdalapiProtocolConfiguration.factoryConfiguration(new URL("http://remotehost/"), edu.kit.dama.staging.adalapi.protocol.SimpleHttp.class.getCanonicalName(), edu.kit.dama.staging.adalapi.authenticator.KITDMAuthenticator.class.getCanonicalName(), properties);

//Persist the configuration using the MetadataManagement of KIT Data Manager
IMetaDataManager mdm = MetaDataManagement.getMetaDataManagement().getMetaDataManager();
mdm.setAuthorizationContext(AuthorizationContext.factorySystemContext());
try {
   mdm.save(config);
} finally {
   mdm.close();
}
--------------------------------------

Now, while processing a download operation the Staging Service can check for each LFN obtained from a Data Organization node whether the protocol-host-port combination fits one of the registered identifiers or not.
If this is the case, the URL is accessed using the configured `protocol class` and authenticated using the provided `authenticator class`. This also means, that for each different protocol-host-port combination one table entry is needed.
In the sample row in the table above all URLs starting with `http://remotehost/` will be accessed using protocol class `edu.kit.dama.staging.adalapi.protocol.SimpleHttp` and authenticator class `edu.kit.dama.staging.adalapi.authenticator.KITDMAuthenticator`
by the Staging Service while preparing a data download. 

Updating KIT Data Manager
-------------------------

The effort for updating from one KIT Data Manager version to another mainly depends on how KIT Data Manager is used and customized. A typical update process of a standard installation 
described earlier in this documentation includes the following steps:

1. Stop the Tomcat container in which KIT Data Manager is running
2. Create a backup of $KITDM_LOCATION and the database
3. Update the KIT Data Manager libraries
4. Update database schema and/or settings if required 
5. Rebuild and redeploy all additionally added, custom libraries (*)
6. Restart the Tomcat container

(*) Step 5 is optional and will be described in section <<SectionCustomUpdate,Update Custom Libraries>>.

The following detailed description for updating a KIT Data Manager installation is based on Ubuntu. 
If you are using another distribution some commands and service names might be slightly different. Also the username and database name used by the pg_dump command 
might be different depending on how your KIT Data Manager instance is configured.

[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo service tomcat7 stop
* Stopping Tomcat servlet engine tomcat7
user@localhost:/home/user$ cd $KITDM_LOCATION
user@localhost:/home/user$ mkdir ../backup_1.0
user@localhost:/home/user$ cp * ../backup_1.0 -R
user@localhost:/home/user$ sudo -u postgres pg_dump -U postgres -h localhost -d datamanager -W > ../backup_1.0/database_dump.sql
user@localhost:/home/user$
--------------------------------------

In the next step, the libraries of your KIT Data Manager installation have to be updated. Please download the update package KITDM-<VERSION>_Update.zip to `$KITDM_LOCATION` and continue as follows:

[source,sh]
--------------------------------------
user@localhost:/home/user$ rm KITDM/WEB-INF/lib/*.jar 
user@localhost:/home/user$ rm KITDM/WEB-INF/classes/edu/kit/dama/ -R
user@localhost:/home/user$ unzip -u KITDM-<VERSION>_Update.zip
user@localhost:/home/user$ 
--------------------------------------

In the first two steps, all libraries and classes of the old version are deleted. This is necessary due to the fact, that a library named `Authorization-1.0.jar` would be favored 
by the classloader even if there is a new version named `Authorization-1.1.jar`. Afterwards, by extracting `KITDM-Update-<VERSION>.zip` all libraries of version <VERSION> are placed 
directly at `$KITDM_LOCATION/KITDM/WEB-INF/lib/`.

After updating all core libraries there might be additional steps necessary, e.g. applying database schema or configuration file changes. Necessary steps are described for each
new version in section <<SectionChanges,Additional Update Steps>>. If you skip one or more versions you typically have to apply all intermediate steps unless the documentation 
states something different.

[NOTE]
From KIT DM 1.5 on running under Ubuntu you should also install the package 'haveged' if not done yet. This package replaces the default, blocking random number generator of the system causing an `extremely long startup` of the KIT DM Web application.

[[SectionCustomUpdate]]
Update Custom Libraries
~~~~~~~~~~~~~~~~~~~~~~~

As soon as you've started integrating community-specific features into the basic repository system, the question arises, how these customizations are carried from one version to the other.
Basically, this is quite simple. At first, it is highly recommended to rebuild all customizations, e.g. Staging Processors or custom metadata entities, against the current version of 
KIT Data Manager in order to detect the use of deprecated interfaces or updated imports. Afterwards, the external libraries must be updated inside `$CATALINA_HOME/webapps/KITDM/WEB-INF/lib/`.
If you are following the recommendation to place all your extensions at `$CATALINA_HOME/webapps/KITDM/WEB-INF/lib/ext/` you may now want to recreate the hard links by executing `ln ext/* .` 
inside `$CATALINA_HOME/webapps/KITDM/WEB-INF/lib/`. If you did not follow the recommendations you should now manually copy all your extension JARS to `$CATALINA_HOME/webapps/KITDM/WEB-INF/lib/`.

[[SectionChanges]]
Additional Update Steps
~~~~~~~~~~~~~~~~~~~~~~~
The following section contains additional update steps necessary in order to update from different versions of KIT Data Manager to the next. There are different types of updates: 

image:data.png[DatabaseUpdate] Database schema changes

image:gear_preferences.png[ConfigurationUpdate] Configuration file changes 

image:server_client_exchange.png[InterfaceUpdate] REST Interface changes

For database changes (image:data.png[DatabaseUpdate]) typically an SQL update script is provided that has to be executed using the following command:

[source,sh]
--------------------------------------
user@localhost:/home/user$ sudo -u postgres psql -U postgres -W -h localhost -d datamanager -f $KITDM_LOCATION/sql/update.1.0-1.1.sql
user@localhost:/home/user$
--------------------------------------

Of course you should use the username and database name fitting your KIT Data Manager installation. Also the name of the update script will change depending on the affected versions.

Please refer to the following section for all changes, whether applying them is optional or not and their side effects:

[underline]*Update 1.0 -> 1.1*

[cols="1,1,6,2", options="header"]
|============================================================================================================================
|Type|Optional|Todo|Side Effects
|image:data.png[DatabaseUpdate]|No|Apply script `sql/update.1.0-1.1.sql`|All ingest- and downloadinformation entries are deleted. Therefor, it is recommended to finish all data transfers before updating.
|image:gear_preferences.png[ConfigurationUpdate]|Yes|Add nodes for *maxIngestLifetime* and *maxDownloadLifetime* to *staging* section 
in `$KITDM_LOCATION/KITDM/WEB-INF/classes/datamanager.xml` The default value is 604800 (seconds per week).|None.
|============================================================================================================================

[underline]*Update 1.1 -> 1.2*

[cols="1,1,6,2", options="header"]
|============================================================================================================================
|Type|Optional|Todo|Side Effects
|image:data.png[DatabaseUpdate]|No|Apply script `sql/update.1.1-1.2.sql`|This script adds the Quartz scheduler related tables to the database. Furthermore, a typo was fixed and an additional column to the table 'ExecutionEnvironmentConfiguration' was introduced. As the worklflow service was not publicly available before version 1.2 this table should not exists, yet. Therefor, error related to changing this table can be safely ignored.
|image:gear_preferences.png[ConfigurationUpdate]|No|Add a new section *scheduler* containing setting for the internal scheduler feature.|None.
|image:gear_preferences.png[ConfigurationUpdate]|No|Update entity list in persistence.xml, persistence unit MDM-Core according to the list below. |None.
|============================================================================================================================

Additional section that has to be added to datamanger.xml in order to configure the Quartz scheduler. The values of the job store have to be changed according to your local configuration:

[source, xml]
--------------------------------------
<config>
   <!--[...]-->
   </staging>
   <scheduler>
     <!--Connection information for the JobStore used to hold information about scheduled jobs. Typically, the same information also used
         in the persistence.xml can be applied here in order to keep everything together in one place.-->
     <jobStoreConnectionDriver>org.postgresql.Driver</jobStoreConnectionDriver>
     <jobStoreConnectionString>jdbc:postgresql://DB_HOST:DB_PORT/DB_NAME</jobStoreConnectionString>
     <jobStoreUser>DB_USER</jobStoreUser>
     <jobStorePassword>DB_PASSWORD</jobStorePassword>
     <!--Wait for running tasks if the scheduler is shutting down, e.g. due to shutting down the application server. default: true-->
     <waitOnShutdown>true</waitOnShutdown>
     <!--Delay in seconds before the scheduler starts the execution of tasks. This delay is useful as services needed to perform tasks
         may not be running, yet, when the scheduler starts. The default value is 5 seconds.-->
     <startDelaySeconds>5</startDelaySeconds>
      <!--Add default schedules during the first startup of the scheduler. These schedules are executing transfer finalization 
          (ingest/download) every 60/30 seconds. The default value is true.-->
     <addDefaultSchedules>true</addDefaultSchedules>
   </scheduler>
</config>
--------------------------------------

Current list of entities (KIT DM 1.2) that has to be registered in the persistence.xml for persistence unit MDM-Core:

[source, xml]
--------------------------------------
 <!-- ********************************************************************
    ***                           MDM-Core                                ***
    *************************************************************************-->
<persistence-unit name="MDM-Core" transaction-type="RESOURCE_LOCAL">
<!--[...]-->
    <class>edu.kit.dama.authorization.entities.impl.Group</class>
    <class>edu.kit.dama.authorization.entities.impl.User</class>
    <class>edu.kit.dama.authorization.entities.impl.Membership</class>
    <class>edu.kit.dama.authorization.entities.impl.GrantImpl</class>
    <class>edu.kit.dama.authorization.entities.impl.GrantSet</class>
    <class>edu.kit.dama.authorization.entities.impl.ResourceReference</class>
    <class>edu.kit.dama.authorization.entities.impl.Grant</class>
    <class>edu.kit.dama.authorization.entities.impl.FilterHelper</class>
    <class>edu.kit.dama.authorization.entities.impl.SecurableResource</class>
    <class>edu.kit.dama.mdm.base.OrganizationUnit</class>
    <class>edu.kit.dama.mdm.base.Study</class>
    <class>edu.kit.dama.mdm.base.Investigation</class>
    <class>edu.kit.dama.mdm.base.DigitalObject</class>
    <class>edu.kit.dama.mdm.base.Participant</class>
    <class>edu.kit.dama.mdm.base.Relation</class>
    <class>edu.kit.dama.mdm.base.Task</class>
    <class>edu.kit.dama.mdm.base.UserData</class>
    <class>edu.kit.dama.mdm.base.MetaDataSchema</class>
    <class>edu.kit.dama.mdm.base.DigitalObjectType</class>
    <class>edu.kit.dama.mdm.base.ObjectTypeMapping</class>
    <class>edu.kit.dama.mdm.base.DigitalObjectTransition</class>
    <class>edu.kit.dama.mdm.base.ObjectViewMapping</class>
    <class>edu.kit.dama.mdm.dataworkflow.ExecutionEnvironmentConfiguration</class>
    <class>edu.kit.dama.mdm.dataworkflow.properties.ExecutionEnvironmentProperty</class>
    <class>edu.kit.dama.mdm.dataworkflow.DataWorkflowTask</class>
    <class>edu.kit.dama.mdm.dataworkflow.DataWorkflowTaskConfiguration</class>
    <class>edu.kit.dama.mdm.dataworkflow.DataWorkflowTransition</class>
    <class>edu.kit.dama.mdm.dataworkflow.properties.StringValueProperty</class>
    <class>edu.kit.dama.mdm.dataworkflow.properties.LinuxSoftwareMapProperty</class>
    <class>edu.kit.dama.mdm.admin.ServiceAccessToken</class>
    <class>edu.kit.dama.mdm.admin.UserGroup</class>
    <class>edu.kit.dama.mdm.admin.UserProperty</class>
    <class>edu.kit.dama.mdm.admin.UserPropertyCollection</class>
    <!--class>edu.kit.dama.mdm.content.MetadataIndexingTask</class-->
<!--[...]-->
</persistence-unit>
--------------------------------------

[underline]*Update 1.2 -> 1.3*

[cols="1,1,6,2", options="header"]
|============================================================================================================================
|Type|Optional|Todo|Side Effects
|image:data.png[DatabaseUpdate]|No|Apply script `sql/update.1.2-1.3.sql`|This script adds two new columns to the StagingProcessor table. Furthermore, the foreign key constraint of the Attribute table has been modified to allow cascading updates. Also the fully qualified class name of LFNImpl has been changed (already in version 1.2). The according database update is now part of this script. Finally, a typo has been fixed.
|image:gear_preferences.png[ConfigurationUpdate]|No|Add a new section *metadataManagement* containing metadata related setting, e.g. for the new feature of object transition handlers. For more details see below.|None.
|image:gear_preferences.png[ConfigurationUpdate]|No|Update entity list in persistence.xml, persistence unit MDM-Core according to the list below. |None.
|============================================================================================================================

Additional section that has to be added to datamanger.xml in order to configure the transition type handler of the metadata management:

[source, xml]
--------------------------------------
<!--[...]-->
<metaDataManagement>
 <transitionTypes>
  <NONE>
   <handlerClass>edu.kit.dama.mdm.tools.NullTransitionTypeHandler</handlerClass>
  </NONE>
 <DATAWORKFLOW>
   <handlerClass>edu.kit.dama.mdm.dataworkflow.tools.DataWorkflowTransitionTypeHandler</handlerClass>
  </DATAWORKFLOW>
  <ELASTICSEARCH>
   <handlerClass>edu.kit.dama.mdm.content.util.ElasticsearchTransitionTypeHandler</handlerClass>
  </ELASTICSEARCH>
 </transitionTypes>
</metaDataManagement>
<!--[...]-->
--------------------------------------

Current list of entities (KIT DM 1.3) that has to be registered in the persistence.xml for persistence unit MDM-Core:

[source, xml]
--------------------------------------
 <!-- ********************************************************************
    ***                           MDM-Core                                ***
    *************************************************************************-->
<persistence-unit name="MDM-Core" transaction-type="RESOURCE_LOCAL">
<!--[...]-->
    <class>edu.kit.dama.authorization.entities.impl.Group</class>
    <class>edu.kit.dama.authorization.entities.impl.User</class>
    <class>edu.kit.dama.authorization.entities.impl.Membership</class>
    <class>edu.kit.dama.authorization.entities.impl.GrantImpl</class>
    <class>edu.kit.dama.authorization.entities.impl.GrantSet</class>
    <class>edu.kit.dama.authorization.entities.impl.ResourceReference</class>
    <class>edu.kit.dama.authorization.entities.impl.Grant</class>
    <class>edu.kit.dama.authorization.entities.impl.FilterHelper</class>
    <class>edu.kit.dama.authorization.entities.impl.SecurableResource</class>
    <class>edu.kit.dama.mdm.base.OrganizationUnit</class>
    <class>edu.kit.dama.mdm.base.Study</class>
    <class>edu.kit.dama.mdm.base.Investigation</class>
    <class>edu.kit.dama.mdm.base.DigitalObject</class>
    <class>edu.kit.dama.mdm.base.Participant</class>
    <class>edu.kit.dama.mdm.base.Relation</class>
    <class>edu.kit.dama.mdm.base.Task</class>
    <class>edu.kit.dama.mdm.base.UserData</class>
    <class>edu.kit.dama.mdm.base.MetaDataSchema</class>
    <class>edu.kit.dama.mdm.base.DigitalObjectType</class>
    <class>edu.kit.dama.mdm.base.ObjectTypeMapping</class>
    <class>edu.kit.dama.mdm.base.DigitalObjectTransition</class>
    <class>edu.kit.dama.mdm.base.ObjectViewMapping</class>
    <class>edu.kit.dama.mdm.dataworkflow.ExecutionEnvironmentConfiguration</class>
    <class>edu.kit.dama.mdm.dataworkflow.properties.ExecutionEnvironmentProperty</class>
    <class>edu.kit.dama.mdm.dataworkflow.DataWorkflowTask</class>
    <class>edu.kit.dama.mdm.dataworkflow.DataWorkflowTaskConfiguration</class>
    <class>edu.kit.dama.mdm.dataworkflow.DataWorkflowTransition</class>
    <class>edu.kit.dama.mdm.dataworkflow.properties.StringValueProperty</class>
    <class>edu.kit.dama.mdm.dataworkflow.properties.LinuxSoftwareMapProperty</class>
    <class>edu.kit.dama.mdm.admin.ServiceAccessToken</class>
    <class>edu.kit.dama.mdm.admin.UserGroup</class>
    <class>edu.kit.dama.mdm.admin.UserProperty</class>
    <class>edu.kit.dama.mdm.admin.UserPropertyCollection</class>
    <class>edu.kit.dama.mdm.content.ElasticsearchTransition</class>
    <class>edu.kit.dama.staging.entities.AdalapiProtocolConfiguration</class>
    <!--class>edu.kit.dama.mdm.content.MetadataIndexingTask</class-->
<!--[...]-->
</persistence-unit>
--------------------------------------

[underline]*Update 1.3 -> 1.4*

[cols="1,1,6,2", options="header"]
|============================================================================================================================
|Type|Optional|Todo|Side Effects
|image:data.png[DatabaseUpdate]|No|Apply script `sql/update.1.3-1.4.sql`|This script adds new columns to tables MetaDataSchema, DigitalObject and StagingProcessor. Furthermore it fixes a type in table DataWorkflowTask. Finally, the script adds system users and groups introduced in version 1.4.
|image:gear_preferences.png[ConfigurationUpdate]|No|New sections 'authorization' and 'audit' added to datamanager.xml, major cleanup of file structure.|None.
|image:gear_preferences.png[ConfigurationUpdate]|No|Update entity list in persistence.xml, persistence unit MDM-Core according to the list below. |None.
|============================================================================================================================

Due to a huge number of changes in the structure of 'datamanager.xml' it is recommended to use the sample file below and merge all settings from the old configuration 
(database connections, elasticsearch settings, staging settings) manually:

[source, xml]
--------------------------------------
<!--KIT Data Manager configuration file. This file contains all general properties used to configure your KIT Data Manager instance. 
-->
<config>
<general>
	<repositoryName>KIT Data Manager</repositoryName>
	<repositoryLogoUrl>http://datamanager.kit.edu/dama/logo_default.png</repositoryLogoUrl>
	<!--Can be accessed e.g. by GUIs to send system mail. Please replace $HOSTNAME by the local hostname.-->
	<systemMailAddress>${general.mail.sender}</systemMailAddress>
	<mailServer>${general.mail.server}</mailServer>
	<globalSecret>qr2I9Hyp0CBhUUXj</globalSecret>
	<!--The base URL of your application server, e.g. http://localhost:8080. Please replace $HOSTNAME by the local hostname. -->
	<baseUrl>${general.base.url}</baseUrl>
	<!--Enable/Disable production mode to show/hide additional logging output.-->
	<productionMode>true</productionMode>
</general>

<!--
SimpleMonitoring-related settings.
-->
<simon>
	<!--The path where the configuration files for the SimpleMonitoring are located. Please replace $KITDM_LOCATION by the absolut path of your KIT Data Manager installation.-->
	<configLocation>${simon.config.location}</configLocation>
</simon>
<!--
Elasticsearch-related settings.
-->
<elasticsearch>
	<!--The cluster name used by KIT Data Manager to publish metadata. (default: KITDataManager)-->
	<cluster>${elasticsearch.cluster}</cluster>
	<!--The hostname of the node where metadata should be published to. (default: localhost)-->
	<host>${elasticsearch.host}</host>
	<!--The port of the Elasticsearch instance. (default: 9300)-->
	<port>${elasticsearch.port}</port>
	<!--The default index that is access for metadata publishing/querying. 
	The index to which metadata is published depends on the published metadata schema. (default: dc)
	-->
	<index>${elasticsearch.default.index}</index>
	<!--The elasticsearch document key which contains the fulltext representation of an entire document. 
	The availability of this key depends on the metadata stored in the document. 
	The default value is 'es.fulltext', this property should not be changed, 
	-->
	<!--fulltextKey>es.fulltext</fulltextKey-->
</elasticsearch>
<!--
MetaDataManagement-related settings.
-->
<metaDataManagement>
    <persistenceImplementations>
      <persistenceImplementation>
        <!--Name of the persistence implementation-->
        <name>JPA</name>
        <!--Implementation class of the persistence implementation-->
        <class>edu.kit.dama.mdm.core.jpa.PersistenceFactoryJpa</class>
        <persistenceUnits>
          <!-- A list of persistence units (configured endpoints) to store metadata. 
          In case of the default JPA implementation these persistence units are 
          actual persistence units configured in a persistence.xml file using the 
		  MetaDataManagement implementation defined above. JPA persistence units not using 
		  this implementation are not listed here. For other implementations of the 
		  MetaDataManagement, these persistence units are probably mapped to something different.

          Attention: 
		  
		  PersistenceUnit labels should be the same for all implementations 
          in order to be able to switch implementations.
		  
                    The default persistence unit can be marked by an attribute 'default=true', 
                    otherwise the first entry is interpreted as default persistence unit used by the 
                    implementation if no persistence unit is specified.
                    -->
                    <persistenceUnit authorization="true">${persistence.authorizationPU}</persistenceUnit>  
                    <persistenceUnit>DataOrganizationPU</persistenceUnit>
                    <!--Default persistence unit if the used persistence unit is not explicitly named.-->
                    <persistenceUnit default="true">MDM-Core</persistenceUnit>  
                    <persistenceUnit staging="true">${persistence.stagingPU}</persistenceUnit>
                </persistenceUnits>
            </persistenceImplementation>  
        </persistenceImplementations>

        <!--Transition type definitions and their handler implementations used by the base metadata REST 
        endpoint to handle transition information provided as JSON structure.-->
        <transitionTypes>
            <NONE>
                <handlerClass>edu.kit.dama.mdm.tools.NullTransitionTypeHandler</handlerClass>
            </NONE>
            <DATAWORKFLOW>
                <handlerClass>edu.kit.dama.mdm.dataworkflow.tools.DataWorkflowTransitionTypeHandler</handlerClass>
            </DATAWORKFLOW>
            <ELASTICSEARCH>
                <handlerClass>edu.kit.dama.mdm.content.util.ElasticsearchTransitionTypeHandler</handlerClass>
            </ELASTICSEARCH>
        </transitionTypes>
    </metaDataManagement>  
    <!--
    Staging-related settings.
    -->
    <staging>   
        <adapters>
            <dataOrganizationAdapter class="edu.kit.dama.staging.adapters.DefaultDataOrganizationServiceAdapter" target="LOCAL"/>        
            <ingestInformationServiceAdapter class="edu.kit.dama.staging.adapters.DefaultIngestInformationServiceAdapter" target="LOCAL"/>
            <downloadInformationServiceAdapter class="edu.kit.dama.staging.adapters.DefaultDownloadInformationServiceAdapter" target="LOCAL"/>
            <storageVirtualizationAdapter class="edu.kit.dama.staging.adapters.DefaultStorageVirtualizationAdapter" target="LOCAL">
                <!--The Url where the managed repository storage (archive) is located. All data ingested into the repository system will be located here.
                Currently, the DefaultStorageVirtualizationAdapter only supports locally accessible Urls. However, this can be remote storages mounted
                into the local filesystem. Please replace $ARCHIVE_STORAGE by the absolute path of your archive location, e.g. file:///mnt/archive/
                Attention: Please pay attention to provide three (!) slashes. Otherwise, all data transfer services of KIT Data Manager won't work.
                -->
                <archiveUrl>${staging.archive.url}</archiveUrl>
                <!--Pattern that is used to structure the data at 'archiveUrl'. Valid variables are:
                     $year: The current year, e.g. 2015
                     $month: The current month, e.g. 9
                     $day: The day of the month, e.g. 1
                     $owner: The userId of the user who has ingested the data, e.g. admin
                     $group: The groupId of the group on whose behalf the user has ingested the data, e.g. USERS
                -->
                <pathPattern>${staging.archive.path.pattern}</pathPattern>
            </storageVirtualizationAdapter>
        </adapters>
        <!--Possible overwrite for persistence unit defined in persistence section.-->
        <!--persistenceUnit>${persistence.stagingPU}</persistenceUnit-->   
        <remoteAccess>
            <!--The remove access Url of the staging service (currently not used). Please replace $HOSTNAME by the local hostname.-->
            <restUrl>${staging.rest.url}</restUrl>
        </remoteAccess>
        <!--The max. number of single files that is transferred in parallel to/from the archive location to access point locations. 
    This number refers to one single staging operation (ingest/download). If there are two staging operations running in parallel, 
        two times 'maxParallelTransfers' are used.-->  
        <maxParallelTransfers>10</maxParallelTransfers>
        <!--The max. number of simultaneous ingest/download operations. This setting is used by the TransferFinalizer tool. The tool itself 
        handles one ingest/download per execution. However, by running the TransferFinalizer as Cron job multiple instances may run in 
        parallel. As soon as maxParallelIngests/maxParallelDownloads is reached TransferFinalizer will return without doing anything.-->
        <maxParallelIngests>2</maxParallelIngests>
        <maxParallelDownloads>2</maxParallelDownloads>
        <!--The max. lifetime in seconds before completed/failed ingests/downloads are removed from the database by the TransferFinalizer. 
        The default value is one week.-->
        <maxIngestLifetime>604800</maxIngestLifetime>
        <maxDownloadLifetime>604800</maxDownloadLifetime>
    </staging>

    <scheduler>
        <!--Connection information for the JobStore used to hold information about scheduled jobs. Typically, the same information also used
        in the persistence.xml can be applied here in order to keep everything together in one place.-->
        <jobStoreConnectionDriver>${persistence.connection.driver}</jobStoreConnectionDriver>
        <jobStoreConnectionString>${persistence.connection.string}</jobStoreConnectionString>
        <jobStoreUser>${persistence.database.user}</jobStoreUser>
        <jobStorePassword>${persistence.database.user.password}</jobStorePassword>
        <!--Wait for running tasks if the scheduler is shutting down, e.g. due to shutting down the application server. default: true-->
        <waitOnShutdown>true</waitOnShutdown>
        <!--Delay in seconds before the scheduler starts the execution of tasks. This delay is useful as services needed to perform tasks
        may not be running, yet, when the scheduler starts. The default value is 5 seconds.-->
        <startDelaySeconds>5</startDelaySeconds>
        <!--Add default schedules during the first startup of the scheduler. These schedules are executing transfer finalization 
        (ingest/download) every 60/30 seconds. The default value is true.-->
        <addDefaultSchedules>true</addDefaultSchedules>
    </scheduler>

    <authorization>
        <login>
            <orcid>
                <!--Configuration for ORCiD login. The ORCiD login is only enabled if id and secret are provided.
                Furthermore, the base Url of the repository instance, e.g. http://localhost:8080/KITDM,  has to be registered as 
                valid redirection of the ORCiD OAuth2 login. -->
                <clientid>ORCID_CLIENT_ID</clientid>
                <clientsecret>ORCID_CLIENT_SECRET</clientsecret>
            </orcid>
            <b2access>
                <!--Configuration for B2Access login. The B2Access login is only enabled if id and secret are provided.
                Furthermore, the base Url of the repository instance, e.g. http://localhost:8080/KITDM,  has to be registered as 
                valid redirection of the B2Access OAuth2 login. -->
                <clientid>NOT_SUPPORTED_YET</clientid>
                <clientsecret>NOT_SUPPORTED_YET</clientsecret>
            </b2access>
        </login>
        <rest>
            <!--Configuration of available authenticators. An authenticator allows to secure the access to 
            KITDM RESTful web services. By default, the access is secured via OAuth using fixed consumer key and secret.
            The user credentials are stored as ServiceAccessToken entities with the default serviceId 'restServiceAccess'.
            -->
            <authenticators>
                <!--The authenticator element and its implementation class-->
                <authenticator class="edu.kit.dama.rest.util.auth.impl.OAuthAuthenticator">
                    <!--The id used as serviceId in associatedService AccessToken entities.-->
                    <authenticatorId>restServiceAccess</authenticatorId>
                    <!--Regular expression allowing to enable this authenticator for specific services. The value below 
                    enables the authenticator for all services, but it is also imaginable to enable an authenticator 
                    only for one specific service. 
                    The expression is applied to the base URL of the request and does not include the resource portion.-->
                    <enableFor>(.*)</enableFor>                       			<!--enableFor>(.*)(basemetadata|sharing|dataorganization|staging|usergroup|dataworkflow|scheduler)(.*)</enableFor-->
                    <!--Authenticator-specific properties, in this case these are OAuth consumer key and secret. -->
                    <defaultConsumerKey>key</defaultConsumerKey>
                    <defaultConsumerSecret>secret</defaultConsumerSecret>
                </authenticator>
                <!--HTTP Authenticator for WebDav access. Please keep in mind that the settings here (realm, type) must match the settings in the web.xml of the WebDav servlet.-->
                <authenticator class="edu.kit.dama.rest.util.auth.impl.HTTPAuthenticator">
                    <authenticatorId>webdav</authenticatorId>
                    <!--The HTTP realm needed if type is 'DIGEST'.-->
                    <realm>kitdm</realm>
                    <!--The type that must be either BASIC or DIGEST.-->
                    <type>DIGEST</type>
                </authenticator>
                <!--Helper authenticator to support ORCID login.-->
                <authenticator class="edu.kit.dama.rest.util.auth.impl.BearerTokenAuthenticator">
                    <authenticatorId>ORCID</authenticatorId>
                </authenticator>
                <!--Helper authenticator to support B2ACCESS login.-->
                <!--B2Access is NOT officially supported, yet. Thus, this setting has no effect.             
                <authenticator class="edu.kit.dama.rest.util.auth.impl.BearerTokenAuthenticator">
                    <authenticatorId>B2ACCESS</authenticatorId>
                </authenticator>
                -->
            </authenticators>
        </rest>
        <!--The default persistence unit for KIT Data Manager Authorization services.
        Due to its complexity, the generic nature of KIT Data Manager MetaDataManagement is not feasible for Authorization services.
        Therefore, they will be configured separately also in future releases.
        -->
        <defaultPU>AuthorizationPU</defaultPU>
    </authorization>

    <audit>
        <!--Audit message publisher implementation. This publisher is contacted by the audit component as soon as an audit message occurs. 
        It is the responsibility of the publisher to distribute the messages to connected consumers. By default, KITDM used a RabbitMQ based
        publisher in order to allow asynchronous, reliable publishing of audit messages. The according receiver is implemented as ServletContextListener
        publishing all received events to connected message consumers.-->
        <publisher class="edu.kit.dama.mdm.audit.impl.RabbitMQPublisher">
            <!--Each publisher might have custom properties, in this case they are the RabbitMQ server hostname and the RabbitMQ exchange used 
            to publish audit messages.-->
            <hostname>${rabbitmq.host}</hostname>
            <exchange>audit</exchange>
        </publisher>
   
        <!--Configuration of connected audit message consumers. Received audit messages are forwarded to the consumer which is responsible for
        handling the message according to its implementation.-->
        <consumers>
            <consumer class="edu.kit.dama.mdm.audit.impl.ConsoleConsumer"/>
            <consumer class="edu.kit.dama.mdm.audit.impl.DatabaseConsumer"/>
        </consumers>
    </audit>
</config>
--------------------------------------

Current list of entities (KIT DM 1.4) that has to be registered in the persistence.xml for persistence unit MDM-Core:

[source, xml]
--------------------------------------
 <!-- ********************************************************************
    ***                           MDM-Core                                ***
    *************************************************************************-->
<persistence-unit name="MDM-Core" transaction-type="RESOURCE_LOCAL">
<!--[...]-->
     <class>edu.kit.dama.authorization.entities.impl.Group</class>
        <class>edu.kit.dama.authorization.entities.impl.User</class>
        <class>edu.kit.dama.authorization.entities.impl.Membership</class>
        <class>edu.kit.dama.authorization.entities.impl.GrantImpl</class>
        <class>edu.kit.dama.authorization.entities.impl.GrantSet</class>
        <class>edu.kit.dama.authorization.entities.impl.ResourceReference</class>
        <class>edu.kit.dama.authorization.entities.impl.Grant</class>
        <class>edu.kit.dama.mdm.base.OrganizationUnit</class>
        <class>edu.kit.dama.mdm.base.Study</class>
        <class>edu.kit.dama.mdm.base.Investigation</class>
        <class>edu.kit.dama.mdm.base.DigitalObject</class>
        <class>edu.kit.dama.mdm.base.Participant</class>
        <class>edu.kit.dama.mdm.base.Relation</class>
        <class>edu.kit.dama.mdm.base.Task</class>
        <class>edu.kit.dama.mdm.base.UserData</class>
        <class>edu.kit.dama.mdm.base.MetaDataSchema</class>
        <class>edu.kit.dama.mdm.base.DigitalObjectType</class>
        <class>edu.kit.dama.mdm.base.ObjectTypeMapping</class>
        <class>edu.kit.dama.mdm.base.DigitalObjectTransition</class>
        <class>edu.kit.dama.mdm.base.ObjectViewMapping</class>
        <class>edu.kit.dama.authorization.entities.impl.FilterHelper</class>
        <class>edu.kit.dama.authorization.entities.impl.SecurableResource</class>
        <class>edu.kit.dama.mdm.dataworkflow.ExecutionEnvironmentConfiguration</class>
        <class>edu.kit.dama.mdm.dataworkflow.properties.ExecutionEnvironmentProperty</class>
        <class>edu.kit.dama.mdm.dataworkflow.DataWorkflowTask</class>
        <class>edu.kit.dama.mdm.dataworkflow.DataWorkflowTaskConfiguration</class>
        <class>edu.kit.dama.mdm.dataworkflow.DataWorkflowTransition</class>
        <class>edu.kit.dama.mdm.dataworkflow.properties.StringValueProperty</class>
        <class>edu.kit.dama.mdm.dataworkflow.properties.LinuxSoftwareMapProperty</class>
        <class>edu.kit.dama.mdm.admin.ServiceAccessToken</class>
        <class>edu.kit.dama.mdm.admin.UserGroup</class>
        <class>edu.kit.dama.mdm.admin.UserProperty</class>
        <class>edu.kit.dama.mdm.admin.UserPropertyCollection</class>
        <class>edu.kit.dama.mdm.content.MetadataIndexingTask</class>
        <class>edu.kit.dama.mdm.content.ElasticsearchTransition</class>
        <class>edu.kit.dama.staging.entities.AdalapiProtocolConfiguration</class>
        <class>edu.kit.dama.mdm.audit.types.AuditEvent</class>
<!--[...]-->
</persistence-unit>
--------------------------------------

[NOTE]
Also consider to update to the custom WebDav implementation provided with KIT DM 1.4. Therefor, please follow the instructions beginning with <<WebDavLibraries,deploying tomcat-ext>>, followed by copying and configuring the provided webdav.xml
Finally, you should compare your configuration with the <<WebDavConfig, configuration described in the installation chapter>>. Afterwards, you should be able to add WebDav credentials in the <<ChapterProfile,profile tab>> of the AdminUI.

[underline]*Update 1.4 -> 1.5*

[cols="1,1,6,2", options="header"]
|============================================================================================================================
|Type|Optional|Todo|Side Effects
|image:data.png[DatabaseUpdate]|No|Apply script `sql/update.1.4-1.5.sql`|This script updates constraints in the data organization tables in order to avoid conflicts during updates.
|image:gear_preferences.png[ConfigurationUpdate]|Yes|Due to an update of the behaviour of transfer finalization jobs it is recommended to change the trigger rate of the ingest and download finalizer jobs to one execution per 2 or 3 seconds after removing the existing triggers from both jobs. Please refer to the <<ChapterJobScheduling,AdminUI documentation>> on how to do this.|None.
|image:server_client_exchange.png[RESTInterfaceChanges]|No|PUT and POST do not longer accept query parameters. Instead, previous query parameters must be provided as form parameters. This affects only the 'groupId' parameter used in almost in every endpoint. |Form parameters provide as query parameters are ignored. In case of the groupId, the default groupId 'USERS' would be used.
|image:server_client_exchange.png[RESTInterfaceChanges]|No|DELETE rest/sharing/resources/references now takes an additional parameter `referenceGroupId` to provide the groupId of the resource reference. Previously, `groupId` has been used for this purpose, which is now used for authorization only.|Not providing `referenceGroupId` will results in HTTP BAD_REQUEST.
|============================================================================================================================

[NOTE]
The authentication extension located in library 'tomcat-ext-<version>.jar' has been updated to version 1.1.2. Please remember to replace library '/usr/share/tomcat7/lib/tomcat-ext-1.1.1.jar' by '/usr/share/tomcat7/lib/tomcat-ext-1.1.2.jar'.
